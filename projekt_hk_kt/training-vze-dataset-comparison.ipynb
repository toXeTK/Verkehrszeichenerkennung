{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a6bb1bd-f7ad-42b9-a5ba-1e1b72e36c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Created By:     Kai\n",
    "# Created School: Franz-Oberthuer-Schule Wuerzburg\n",
    "# Created Email:  metzgerkai@franz-oberthuer-schule.de\n",
    "# Created Date:   Fri December 06 18:08 UTC 2024\n",
    "# Version:        1.0\n",
    "# =============================================================================\n",
    "\"\"\"The Module has been build for training the symbols dataset with images + \n",
    "ground truth on a Raspberry Pi 5 with a standard USB camera. An image with a \n",
    "resolution of 640px x 480px can be recorded with the Python script \n",
    "create-symbols-dataset.py.\n",
    "The files in the dataset <2023 symbols> should be ordered in the following\n",
    "manner:             > explanation\n",
    "- 2023 symbols      \n",
    "  - dataset3        > dataset version (dataset1 - 3 where used in the project)\n",
    "    - data          > images (.png files)\n",
    "    - gt            > ground truth (.txt files with class labels 1-4)\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# Import\n",
    "# =============================================================================\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models, utils, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To get reproducable results with the same training setting random seed\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Flags\n",
    "plots_on = True\n",
    "test_on_specific_image = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "002fbec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Define functions\n",
    "# =============================================================================\n",
    "# Change image size and convert to grayscale images\n",
    "def pic_prep (image, x, y):\n",
    "  image = cv2.resize(image, (y,x)) # change image size\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "  image = image / 255 # image normalization\n",
    "  return image\n",
    "\n",
    "# Shuffle images\n",
    "def unison_shuffle(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "# todo: only show output of training for every 10 epochs\n",
    "# Add callback to only print loss etc. after e.g. 10 epochs:\n",
    "# https://stackoverflow.com/questions/44931689/how-to-disable-printing-reports-after-each-epoch-in-keras\n",
    "class callback_print(callbacks.Callback):\n",
    "    SHOW_NUMBER = 10\n",
    "    counter = 0\n",
    "    epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch = epoch\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        if self.counter == self.SHOW_NUMBER or self.epoch == 1:\n",
    "            print('Epoch: ' + str(self.epoch) + ' loss: ' + str(logs['loss']))\n",
    "            if self.epoch > 1:\n",
    "                self.counter = 0\n",
    "        self.counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc0226f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Function with some hypterparameters to change for comparison\n",
    "# =============================================================================\n",
    "def train_signs_model(num_training=0,\n",
    "                        image_size=[32, 28],\n",
    "                        num_neurons_per_layer=[64,32,16,13],\n",
    "                        batch_size=4,\n",
    "                        epochs=300):\n",
    "    # =============================================================================\n",
    "    # Declare variables\n",
    "    # =============================================================================\n",
    "    img_size_x = image_size[0]\n",
    "    img_size_y = image_size[1]\n",
    "    img_dim = img_size_x * img_size_y\n",
    "    data_index = 0\n",
    "\n",
    "    # Change the following paths to your dataset path\n",
    "    dataset_dir = '/home/pi/Documents/Verkehrszeichenerkennung/projekt_hk_kt/dataset'\n",
    "    checkpoint_filepath = '/home/pi/Documents/Verkehrszeichenerkennung/projekt_hk_kt/chpt'\n",
    "    folder = [item for item in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir,item))]\n",
    "    anz_folder = len(folder)\n",
    "    img_path = glob.glob(dataset_dir + '/*/*.jpg')\n",
    "    anz_data = len(img_path)\n",
    "\n",
    "    # =============================================================================\n",
    "    # Get number of data (image/label) \n",
    "    # =============================================================================\n",
    "    anz_data = int(anz_data) - 1\n",
    "    dataset = np.zeros((anz_data, img_size_x, img_size_y), dtype=float)\n",
    "    ground_truth = np.zeros((anz_data), dtype=str)\n",
    "    #print(\"dataset size:\", anz_data)\n",
    "\n",
    "    # =============================================================================\n",
    "    # Callback for training\n",
    "    # =============================================================================\n",
    "    model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath + str(num_training) + \"-chpt.model.keras\",\n",
    "        save_weights_only=False,\n",
    "        monitor='val_accuracy',\n",
    "        mode='auto',\n",
    "        save_best_only=True,\n",
    "        verbose = 1)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Read dataset\n",
    "    # =============================================================================\n",
    "    for i in range(0, anz_data, 1):\n",
    "        image = cv2.imread(img_path[i])                 # read image\n",
    "        image = pic_prep(image, img_size_x, img_size_y) # prepare image\n",
    "        dataset[i,:,:] = image                          # 2d-image to 3d-array\n",
    "        ground_truth[i] = os.path.basename(img_path[i]) # ground truth for all images\n",
    "\n",
    "    # =============================================================================\n",
    "    # Prepare dataset: train set (80%) and test set (20%)\n",
    "    # =============================================================================\n",
    "    dataset = dataset.reshape(anz_data, img_dim) # convert into 2d array (all pixel in one row)\n",
    "    ground_truth = ground_truth.reshape(anz_data, 1)\n",
    "\n",
    "    dataset, ground_truth = unison_shuffle(dataset, ground_truth)\n",
    "\n",
    "    trainset = np.random.choice(dataset.shape[0],\n",
    "                                int(dataset.shape[0]*0.80), \n",
    "                                replace=False)\n",
    "    train_data = dataset[trainset,:]\n",
    "    train_gt = ground_truth[trainset]\n",
    "    train_gt = utils.to_categorical(train_gt, 4)\n",
    "\n",
    "    testset = np.delete(np.arange(0, len(ground_truth) ), \n",
    "                        trainset) \n",
    "    test_data = dataset[testset,:]\n",
    "    test_gt = ground_truth[testset]\n",
    "    test_gt = utils.to_categorical(test_gt, 4)\n",
    "    #print(ground_truth)\n",
    "    #print(dataset)\n",
    "    #print(trainset)\n",
    "    #print(train_data)\n",
    "    #print(train_gt)\n",
    "\n",
    "    # =============================================================================\n",
    "    # Create neural network with e.g. 4 layers and (64, 32, 16, 4) neurons per layer.\n",
    "    # =============================================================================\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(num_neurons_per_layer[0], input_dim=img_dim,activation='relu'))\n",
    "    model.add(layers.Dense(num_neurons_per_layer[1], activation='relu'))\n",
    "    model.add(layers.Dense(num_neurons_per_layer[2], activation='relu'))\n",
    "    model.add(layers.Dense(num_neurons_per_layer[3], activation='sigmoid'))\n",
    "    model.compile(loss='mean_squared_error', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # =============================================================================\n",
    "    # Train the neuronal network e.g. for e.g. 300 epochs.\n",
    "    # =============================================================================\n",
    "    history = model.fit(train_data, \n",
    "                        train_gt, \n",
    "                        batch_size=batch_size, \n",
    "                        epochs=epochs, \n",
    "                        verbose=0, \n",
    "                        shuffle=True, \n",
    "                        validation_data=(test_data, test_gt), \n",
    "                        callbacks=[model_checkpoint_callback])\n",
    "    \n",
    "    # =============================================================================\n",
    "    # Plot train and val accuracy.\n",
    "    # =============================================================================\n",
    "    if plots_on:\n",
    "        plt.plot(history.history['accuracy'], label='accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "        # =========================================================================\n",
    "        # Plot train and val loss.\n",
    "        # =========================================================================\n",
    "        plt.plot(history.history['loss'], label='loss')\n",
    "        plt.plot(history.history['val_loss'], label='val_loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(loc='lower left')\n",
    "        plt.show()\n",
    "    \n",
    "    if test_on_specific_image:\n",
    "        # =========================================================================\n",
    "        # Load pretrained dataset weights to e.g. test on new (unseen) data.\n",
    "        # =========================================================================\n",
    "        model.load_weights(checkpoint_filepath + \".keras\")   \n",
    "\n",
    "        # =========================================================================\n",
    "        # Test dataset on xxx.\n",
    "        # =========================================================================\n",
    "        score = model.evaluate(test_data, test_gt, verbose=1)\n",
    "        print('Test score:', score[0])\n",
    "        print('Test accuracy:', score[1])       \n",
    "\n",
    "        # =========================================================================\n",
    "        # Testing on a single image.\n",
    "        # =========================================================================\n",
    "        \"\"\"\n",
    "        data_pred = np.zeros((1, img_size_x, img_size_y), dtype=float)\n",
    "        img_pred = cv2.imread('/home/pi/Documents/ml_project/symbols/dataset1/data/13.png')\n",
    "        img_pred = pic_prep(img_pred, img_size_x, img_size_y)\n",
    "        data_pred[0,:,:] = img_pred\n",
    "        data_pred = data_pred.reshape(1,img_dim)\n",
    "        result = model.predict(data_pred)\n",
    "        result = np.round(result, decimals=2)\n",
    "        print(\"Probability for class (cross, circle, triangle, square) in percent\", \n",
    "            result)\n",
    "        \n",
    "        # =============================================================================\n",
    "        # Output class: \n",
    "        # translate class label (0,1,2,3) to class (cross, circle, triangle, square).\n",
    "        # =============================================================================\n",
    "        max_res = 0\n",
    "        res_index = 4\n",
    "        for i in range(0, 4, 1):\n",
    "            if result[0,i] > max_res:\n",
    "                max_res = result[0,i]\n",
    "                res_index = i\n",
    "\n",
    "        if res_index == 0:\n",
    "            print('Cross detected!')\n",
    "        elif res_index == 1:\n",
    "            print('Circle detected!')\n",
    "        elif res_index == 2:\n",
    "            print('Triangle detected!')\n",
    "        elif res_index == 3:\n",
    "            print('Square detected!')\n",
    "        elif res_index == 4:\n",
    "            print('Error!')\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d4eafc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1 with image size [32, 28] and [256, 32, 16, 13] neurons per layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@278.197] global loadsave.cpp:241 findDecoder imread_('/home/pi/Documents/Verkehrszeichenerkennung/projekt_hk_kt/dataset/FÃ¼nfzig/00003_00029..jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_size, num_neurons \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(image_dims, neurons_layers):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m, i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith image size\u001b[39m\u001b[38;5;124m\"\u001b[39m, img_size, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_neurons, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneurons per layer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m     \u001b[43mtrain_signs_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_neurons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#################################################\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m     i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[7], line 49\u001b[0m, in \u001b[0;36mtrain_signs_model\u001b[0;34m(num_training, image_size, num_neurons_per_layer, batch_size, epochs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, anz_data, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     48\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path[i])                 \u001b[38;5;66;03m# read image\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mpic_prep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_size_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_size_y\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# prepare image\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     dataset[i,:,:] \u001b[38;5;241m=\u001b[39m image                          \u001b[38;5;66;03m# 2d-image to 3d-array\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     ground_truth[i] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(img_path[i]) \u001b[38;5;66;03m# ground truth for all images\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m, in \u001b[0;36mpic_prep\u001b[0;34m(image, x, y)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpic_prep\u001b[39m (image, x, y):\n\u001b[0;32m----> 6\u001b[0m   image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# change image size\u001b[39;00m\n\u001b[1;32m      7\u001b[0m   image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY) \u001b[38;5;66;03m# convert to grayscale\u001b[39;00m\n\u001b[1;32m      8\u001b[0m   image \u001b[38;5;241m=\u001b[39m image \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;66;03m# image normalization\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Train multiple networks with differend image scales and neurons per layer\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "image_dims = [[32, 28],\n",
    "              [32, 28],\n",
    "              [32, 28]]\n",
    "neurons_layers = [[64,32,16,4],\n",
    "                  [32,32,16,4],\n",
    "                  [16,32,16,4]]\n",
    "\"\"\"\n",
    "image_dims = [[32, 28],\n",
    "              [32, 28],\n",
    "              [32, 28],\n",
    "              [32, 28],\n",
    "              [32, 28]]\n",
    "neurons_layers = [[256,32,16,13],\n",
    "                  [128,32,16,13],\n",
    "                  [64,32,16,13],\n",
    "                  [32,32,16,13],\n",
    "                  [16,32,16,13]]\n",
    "\n",
    "# Train multiple times with different hyper parameters (dim img size, neurons per layer)\n",
    "i = 1\n",
    "for img_size, num_neurons in zip(image_dims, neurons_layers):\n",
    "    print(\"Training\", i, \"with image size\", img_size, \"and\", num_neurons, \"neurons per layer\")\n",
    "    train_signs_model(i, img_size, num_neurons, 4, 300)\n",
    "    print(\"#################################################\\n\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5e4766",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
